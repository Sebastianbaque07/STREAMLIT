{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dccccb1",
   "metadata": {},
   "source": [
    "# üéì Predicci√≥n de Deserci√≥n Estudiantil ‚Äî Miner√≠a de Datos\n",
    "## Metodolog√≠a CRISP-DM Completa (6 Fases)\n",
    "\n",
    "---\n",
    "\n",
    "| Dato | Valor |\n",
    "|------|-------|\n",
    "| **Carrera** | Ciencia de Datos e Inteligencia Artificial |\n",
    "| **Facultad** | Ciencias Matem√°ticas y F√≠sicas |\n",
    "| **Metodolog√≠a** | CRISP-DM |\n",
    "| **Dataset** | Record estudiantil anonimizado |\n",
    "| **Entrada** | Archivo Excel (.xlsx) |\n",
    "| **Salida** | Modelo entrenado + artefactos para Streamlit |\n",
    "\n",
    "### Estructura del Notebook\n",
    "1. **Fase 1** ‚Äî Comprensi√≥n del Negocio\n",
    "2. **Fase 2** ‚Äî Comprensi√≥n de los Datos (EDA)\n",
    "3. **Fase 3** ‚Äî Preparaci√≥n de los Datos (Feature Engineering)\n",
    "4. **Fase 4** ‚Äî Modelado\n",
    "5. **Fase 5** ‚Äî Evaluaci√≥n\n",
    "6. **Fase 6** ‚Äî Despliegue (exportaci√≥n para Streamlit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c9038",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuraci√≥n del Entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7974fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependencias necesarias en Colab\n",
    "!pip install scikit-learn imbalanced-learn xgboost openpyxl joblib -q\n",
    "print(\"‚úÖ Dependencias instaladas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c577c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar todas las librer√≠as del proyecto\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, classification_report, roc_auc_score, roc_curve)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_style(\"whitegrid\")\n",
    "print(\"‚úÖ Librer√≠as importadas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ccf9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subir y cargar el archivo Excel con el record estudiantil\n",
    "from google.colab import files\n",
    "print(\"üìÇ Selecciona el archivo REPORTE_RECORD_ESTUDIANTIL_ANONIMIZADO.xlsx\")\n",
    "uploaded = files.upload()\n",
    "FILENAME = list(uploaded.keys())[0]\n",
    "df_raw = pd.read_excel(FILENAME)\n",
    "print(f\"‚úÖ Cargado: {df_raw.shape[0]:,} filas √ó {df_raw.shape[1]} columnas | {df_raw['ESTUDIANTE'].nunique()} estudiantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce2f08",
   "metadata": {},
   "source": [
    "---\n",
    "# FASE 1 ‚Äî Comprensi√≥n del Negocio\n",
    "\n",
    "## Contexto\n",
    "La deserci√≥n estudiantil es uno de los principales desaf√≠os de las instituciones de educaci√≥n superior.\n",
    "Identificar tempranamente a estudiantes en riesgo permite implementar estrategias de retenci√≥n.\n",
    "\n",
    "## Objetivo\n",
    "Construir un modelo de clasificaci√≥n binaria que prediga qu√© estudiantes tienen mayor probabilidad de desertar.\n",
    "\n",
    "## Definici√≥n operativa de Deserci√≥n\n",
    "> Un estudiante se clasifica como **DESERTOR (1)** si su √∫ltimo per√≠odo de matr√≠cula registrado es **anterior** al ciclo acad√©mico m√°s reciente (2025-2026).\n",
    "> Si aparece en al menos un per√≠odo de 2025-2026 ‚Üí **ACTIVO (0)**.\n",
    "\n",
    "## Criterios de √âxito\n",
    "| M√©trica | Umbral | Justificaci√≥n |\n",
    "|---------|--------|---------------|\n",
    "| **Recall** | > 0.60 | Prioridad: minimizar falsos negativos (desertores no detectados) |\n",
    "| **F1-Score** | > 0.60 | Equilibrio precisi√≥n/recall |\n",
    "| **Accuracy** | > 0.70 | Rendimiento general aceptable |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485c83a",
   "metadata": {},
   "source": [
    "---\n",
    "# FASE 2 ‚Äî Comprensi√≥n de los Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c78eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copia de trabajo, inspecci√≥n de estructura y tipos de datos\n",
    "df = df_raw.copy()\n",
    "print(\"ESTRUCTURA DEL DATASET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dimensiones: {df.shape[0]:,} filas √ó {df.shape[1]} columnas\\n\")\n",
    "print(\"Tipos de datos y valores √∫nicos:\")\n",
    "for col in df.columns:\n",
    "    n = df[col].nunique()\n",
    "    nulos = df[col].isnull().sum()\n",
    "    extra = f\"  ‚Üí  {sorted(df[col].dropna().unique().tolist())}\" if n <= 12 else \"\"\n",
    "    nul_txt = f\"  ‚ö† {nulos} nulos\" if nulos > 0 else \"\"\n",
    "    print(f\"  {col:25s} [{str(df[col].dtype):8s}] {n:5d} √∫nicos{nul_txt}{extra}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df4163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza: convertir PROMEDIO de texto con coma a float, y eliminar columnas constantes\n",
    "df['PROMEDIO'] = df['PROMEDIO'].str.replace(',', '.').astype(float)\n",
    "cols_const = [c for c in df.columns if df[c].nunique() == 1]\n",
    "print(f\"Columnas constantes eliminadas: {cols_const}\")\n",
    "df = df.drop(columns=cols_const)\n",
    "\n",
    "print(f\"\\nRangos de variables num√©ricas:\")\n",
    "print(f\"  PROMEDIO:   [{df['PROMEDIO'].min():.1f}, {df['PROMEDIO'].max():.1f}]  (escala 0-10)\")\n",
    "print(f\"  ASISTENCIA: [{df['ASISTENCIA'].min()}, {df['ASISTENCIA'].max()}]  (escala 0-100%)\")\n",
    "print(f\"  NO. VEZ:    [{df['NO. VEZ'].min()}, {df['NO. VEZ'].max()}]\")\n",
    "print(f\"  NIVEL:      [{df['NIVEL'].min()}, {df['NIVEL'].max()}]\")\n",
    "\n",
    "df[['PROMEDIO', 'ASISTENCIA', 'NO. VEZ', 'NIVEL']].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c6030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir orden cronol√≥gico de per√≠odos y crear variable objetivo DESERTOR\n",
    "PERIODOS = [\n",
    "    '2023 - 2024 CII', '2023 - 2024 ING2B',\n",
    "    '2024 - 2025 CI', '2024 - 2025 ING1B', '2024 - 2025 CII', '2024 - 2025 ING2B',\n",
    "    '2025 - 2026 CI', '2025 - 2026 ING1A', '2025 - 2026 ING1B'\n",
    "]\n",
    "ULTIMOS = PERIODOS[6:]  # per√≠odos del ciclo 2025-2026\n",
    "p2idx = {p: i for i, p in enumerate(PERIODOS)}\n",
    "idx2p = {i: p for p, i in p2idx.items()}\n",
    "df['PERIODO_IDX'] = df['PERIODO'].map(p2idx)\n",
    "\n",
    "# Calcular primer y √∫ltimo per√≠odo de cada estudiante\n",
    "est = df.groupby('ESTUDIANTE').agg(\n",
    "    ULTIMO_IDX=('PERIODO_IDX', 'max'),\n",
    "    PRIMER_IDX=('PERIODO_IDX', 'min')\n",
    ").reset_index()\n",
    "IDX_CORTE = p2idx['2025 - 2026 CI']\n",
    "est['DESERTOR'] = (est['ULTIMO_IDX'] < IDX_CORTE).astype(int)\n",
    "est['ULTIMO_PERIODO'] = est['ULTIMO_IDX'].map(idx2p)\n",
    "df = df.merge(est[['ESTUDIANTE', 'DESERTOR']], on='ESTUDIANTE')\n",
    "\n",
    "# Mostrar distribuci√≥n\n",
    "total = len(est)\n",
    "n_des = est['DESERTOR'].sum()\n",
    "n_act = total - n_des\n",
    "print(\"VARIABLE OBJETIVO\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"  Activos (0):    {n_act} ({n_act/total*100:.1f}%)\")\n",
    "print(f\"  Desertores (1): {n_des} ({n_des/total*100:.1f}%)\")\n",
    "print(f\"\\n√öltimo per√≠odo de desertores:\")\n",
    "print(est[est['DESERTOR']==1]['ULTIMO_PERIODO'].value_counts().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b75f61",
   "metadata": {},
   "source": [
    "### Visualizaciones del EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec891c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 1 ‚Äî Estudiantes por per√≠odo acad√©mico\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "ep = df.groupby('PERIODO')['ESTUDIANTE'].nunique().reindex(PERIODOS)\n",
    "colores = ['#2ecc71' if p in ULTIMOS else '#3498db' for p in PERIODOS]\n",
    "bars = ax.bar(range(len(PERIODOS)), ep.values, color=colores, edgecolor='white')\n",
    "ax.set_xticks(range(len(PERIODOS)))\n",
    "ax.set_xticklabels([p.replace('2023 - 2024','23-24').replace('2024 - 2025','24-25').replace('2025 - 2026','25-26') for p in PERIODOS], fontsize=9)\n",
    "for b, v in zip(bars, ep.values):\n",
    "    ax.text(b.get_x()+b.get_width()/2, v+2, str(v), ha='center', fontweight='bold')\n",
    "ax.set_title('Estudiantes por Per√≠odo Acad√©mico', fontweight='bold')\n",
    "ax.set_ylabel('Estudiantes')\n",
    "ax.legend(handles=[plt.Rectangle((0,0),1,1,fc='#3498db'), plt.Rectangle((0,0),1,1,fc='#2ecc71')],\n",
    "          labels=['Anteriores', 'Recientes (activos)'])\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bcc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 2 ‚Äî Distribuci√≥n de la variable objetivo (pie + barras)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(13, 5))\n",
    "axes[0].pie([n_act, n_des], labels=['No Desertor', 'Desertor'], colors=['#2ecc71','#e74c3c'],\n",
    "            autopct='%1.1f%%', startangle=90, explode=(0, 0.05), textprops={'fontsize': 12})\n",
    "axes[0].set_title('Distribuci√≥n de Deserci√≥n', fontweight='bold')\n",
    "\n",
    "bars = axes[1].bar(['No Desertor','Desertor'], [n_act, n_des], color=['#2ecc71','#e74c3c'], width=0.5, edgecolor='white')\n",
    "for b, v in zip(bars, [n_act, n_des]):\n",
    "    axes[1].text(b.get_x()+b.get_width()/2, v+3, f'{v} ({v/total*100:.1f}%)', ha='center', fontweight='bold')\n",
    "axes[1].set_title('Cantidad por Clase', fontweight='bold')\n",
    "axes[1].set_ylabel('Estudiantes')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06e2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 3 ‚Äî Distribuci√≥n de promedios (histograma + boxplot por estado)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df['PROMEDIO'], bins=40, color='#3498db', edgecolor='white', alpha=0.8)\n",
    "axes[0].axvline(df['PROMEDIO'].mean(), color='red', ls='--', label=f'Media: {df[\"PROMEDIO\"].mean():.2f}')\n",
    "axes[0].axvline(7.0, color='orange', ls='--', label='M√≠n. aprobaci√≥n (7.0)')\n",
    "axes[0].set_title('Distribuci√≥n de Promedios', fontweight='bold')\n",
    "axes[0].set_xlabel('Promedio'); axes[0].legend()\n",
    "\n",
    "bp = axes[1].boxplot([df[df['ESTADO']=='APROBADA']['PROMEDIO'], df[df['ESTADO']=='REPROBADA']['PROMEDIO']],\n",
    "                      labels=['Aprobada','Reprobada'], patch_artist=True, widths=0.4)\n",
    "bp['boxes'][0].set_facecolor('#2ecc71'); bp['boxes'][1].set_facecolor('#e74c3c')\n",
    "axes[1].set_title('Promedios por Estado', fontweight='bold')\n",
    "axes[1].set_ylabel('Promedio')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d5c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 4 ‚Äî Distribuci√≥n de asistencia y boxplot por deserci√≥n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].hist(df['ASISTENCIA'], bins=30, color='#9b59b6', edgecolor='white', alpha=0.8)\n",
    "axes[0].axvline(df['ASISTENCIA'].mean(), color='red', ls='--', label=f'Media: {df[\"ASISTENCIA\"].mean():.1f}%')\n",
    "axes[0].set_title('Distribuci√≥n de Asistencia', fontweight='bold')\n",
    "axes[0].set_xlabel('% Asistencia'); axes[0].legend()\n",
    "\n",
    "bp = axes[1].boxplot([df[df['DESERTOR']==0]['ASISTENCIA'], df[df['DESERTOR']==1]['ASISTENCIA']],\n",
    "                      labels=['No Desertor','Desertor'], patch_artist=True, widths=0.4)\n",
    "bp['boxes'][0].set_facecolor('#2ecc71'); bp['boxes'][1].set_facecolor('#e74c3c')\n",
    "axes[1].set_title('Asistencia por Condici√≥n de Deserci√≥n', fontweight='bold')\n",
    "axes[1].set_ylabel('% Asistencia')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae54a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 5 ‚Äî Tasa de reprobaci√≥n por materia\n",
    "tasa_rep = df.groupby('MATERIA')['ESTADO'].apply(lambda x: (x=='REPROBADA').sum()/len(x)*100).sort_values(ascending=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 9))\n",
    "colores = ['#e74c3c' if t > 25 else '#f39c12' if t > 15 else '#2ecc71' for t in tasa_rep.values]\n",
    "ax.barh(range(len(tasa_rep)), tasa_rep.values, color=colores, edgecolor='white')\n",
    "ax.set_yticks(range(len(tasa_rep)))\n",
    "ax.set_yticklabels(tasa_rep.index, fontsize=8)\n",
    "ax.set_xlabel('Tasa de Reprobaci√≥n (%)')\n",
    "ax.set_title('Tasa de Reprobaci√≥n por Materia', fontweight='bold')\n",
    "for b, v in zip(ax.patches, tasa_rep.values):\n",
    "    ax.text(v + 0.3, b.get_y() + b.get_height()/2, f'{v:.1f}%', va='center', fontsize=7)\n",
    "ax.legend(handles=[plt.Rectangle((0,0),1,1,fc=c) for c in ['#e74c3c','#f39c12','#2ecc71']],\n",
    "          labels=['>25% (alta)', '15-25% (media)', '<15% (baja)'], loc='lower right')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c852437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 6 ‚Äî Promedios: histograma superpuesto desertores vs activos\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(df[df['DESERTOR']==0]['PROMEDIO'], bins=30, alpha=0.6, color='#2ecc71', label='No Desertor', density=True)\n",
    "ax.hist(df[df['DESERTOR']==1]['PROMEDIO'], bins=30, alpha=0.6, color='#e74c3c', label='Desertor', density=True)\n",
    "ax.set_title('Distribuci√≥n de Promedios: Desertores vs Activos', fontweight='bold')\n",
    "ax.set_xlabel('Promedio'); ax.set_ylabel('Densidad'); ax.legend()\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89755336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 7 ‚Äî Aprobaci√≥n/Reprobaci√≥n agrupado por deserci√≥n\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "trd = df.groupby(['DESERTOR','ESTADO']).size().unstack(fill_value=0)\n",
    "trd_pct = trd.div(trd.sum(axis=1), axis=0) * 100\n",
    "trd_pct.plot(kind='bar', stacked=True, ax=ax, color=['#2ecc71','#e74c3c'], edgecolor='white', width=0.4)\n",
    "ax.set_xticklabels(['No Desertor', 'Desertor'], rotation=0)\n",
    "ax.set_title('Aprobaci√≥n/Reprobaci√≥n por Deserci√≥n', fontweight='bold')\n",
    "ax.set_ylabel('%'); ax.legend(['Aprobada', 'Reprobada'])\n",
    "for i, (_, row) in enumerate(trd_pct.iterrows()):\n",
    "    cum = 0\n",
    "    for col in trd_pct.columns:\n",
    "        ax.text(i, cum + row[col]/2, f'{row[col]:.1f}%', ha='center', va='center', fontweight='bold', color='white')\n",
    "        cum += row[col]\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 8 ‚Äî Tasa de deserci√≥n por nivel m√°ximo alcanzado\n",
    "niv = df.groupby('ESTUDIANTE').agg(NIVEL_MAX=('NIVEL','max'), DESERTOR=('DESERTOR','first')).reset_index()\n",
    "tdn = niv.groupby('NIVEL_MAX')['DESERTOR'].mean() * 100\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "colores_n = ['#e74c3c' if v > 30 else '#f39c12' if v > 15 else '#2ecc71' for v in tdn.values]\n",
    "ax.bar(tdn.index.astype(str), tdn.values, color=colores_n, edgecolor='white')\n",
    "for i, v in enumerate(tdn.values):\n",
    "    ax.text(i, v + 1, f'{v:.1f}%', ha='center', fontweight='bold')\n",
    "ax.set_title('Tasa de Deserci√≥n por Nivel M√°ximo Alcanzado', fontweight='bold')\n",
    "ax.set_xlabel('Nivel M√°ximo'); ax.set_ylabel('Tasa de Deserci√≥n (%)')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80f370c",
   "metadata": {},
   "source": [
    "---\n",
    "# FASE 3 ‚Äî Preparaci√≥n de los Datos\n",
    "\n",
    "## Transformaci√≥n\n",
    "Se transforma el dataset granular **(4,448 filas: 1 materia √ó per√≠odo)** a un dataset de modelado **(488 filas: 1 por estudiante)** creando features agregados que resumen el comportamiento acad√©mico.\n",
    "\n",
    "## Categor√≠as de features:\n",
    "| Categor√≠a | Qu√© mide | Ejemplos |\n",
    "|-----------|----------|----------|\n",
    "| Rendimiento | Calificaciones | promedio_general, promedio_max, promedio_std |\n",
    "| Asistencia | Presencia en clase | asistencia_promedio, asistencia_min |\n",
    "| Aprobaci√≥n | √âxito acad√©mico | tasa_reprobacion, materias_aprobadas |\n",
    "| Repetici√≥n | Materias recursadas | max_vez_cursada, materias_repetidas |\n",
    "| Progreso | Avance en la carrera | nivel_max, num_periodos_regulares |\n",
    "| Alertas | Se√±ales de riesgo | materias_nota_cero, pct_asist_cero |\n",
    "| Contexto | Info complementaria | registros_especiales, carga acad√©mica |\n",
    "| Tendencia | Evoluci√≥n temporal | cambio_promedio, cambio_asistencia |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3feedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar registros especiales (movilidad, homologaci√≥n)\n",
    "especiales = df[df['GRUPO/PARALELO'].str.contains('MOVILIDAD|HOMOLOGACION|CONVALIDACION', case=False, na=False)]\n",
    "print(f\"Registros especiales: {len(especiales)} ({especiales['ESTUDIANTE'].nunique()} estudiantes)\")\n",
    "\n",
    "# ========================================================================\n",
    "# BLOQUE DE FEATURE ENGINEERING COMPLETO\n",
    "# Se agregan todas las m√©tricas a nivel de estudiante en un solo paso\n",
    "# ========================================================================\n",
    "\n",
    "# (1) Rendimiento acad√©mico ‚Äî estad√≠sticas de calificaciones y asistencia\n",
    "feat = df.groupby('ESTUDIANTE').agg(\n",
    "    promedio_general   = ('PROMEDIO', 'mean'),\n",
    "    promedio_mediana   = ('PROMEDIO', 'median'),\n",
    "    promedio_min       = ('PROMEDIO', 'min'),\n",
    "    promedio_max       = ('PROMEDIO', 'max'),\n",
    "    promedio_std       = ('PROMEDIO', 'std'),\n",
    "    asistencia_promedio= ('ASISTENCIA', 'mean'),\n",
    "    asistencia_mediana = ('ASISTENCIA', 'median'),\n",
    "    asistencia_min     = ('ASISTENCIA', 'min'),\n",
    "    asistencia_max     = ('ASISTENCIA', 'max'),\n",
    "    asistencia_std     = ('ASISTENCIA', 'std'),\n",
    ").reset_index()\n",
    "feat[['promedio_std','asistencia_std']] = feat[['promedio_std','asistencia_std']].fillna(0)\n",
    "\n",
    "# (2) Aprobaci√≥n y reprobaci√≥n\n",
    "apr = df.groupby('ESTUDIANTE').agg(\n",
    "    total_materias      = ('ESTADO', 'count'),\n",
    "    materias_aprobadas  = ('ESTADO', lambda x: (x == 'APROBADA').sum()),\n",
    "    materias_reprobadas = ('ESTADO', lambda x: (x == 'REPROBADA').sum()),\n",
    ").reset_index()\n",
    "apr['tasa_aprobacion']  = apr['materias_aprobadas']  / apr['total_materias']\n",
    "apr['tasa_reprobacion'] = apr['materias_reprobadas'] / apr['total_materias']\n",
    "feat = feat.merge(apr, on='ESTUDIANTE')\n",
    "\n",
    "# (3) Repetici√≥n de materias\n",
    "rep = df.groupby('ESTUDIANTE').agg(max_vez_cursada=('NO. VEZ','max'), promedio_vez_cursada=('NO. VEZ','mean')).reset_index()\n",
    "m_rep = df[df['NO. VEZ'] > 1].groupby('ESTUDIANTE').size().reset_index(name='materias_repetidas')\n",
    "rep = rep.merge(m_rep, on='ESTUDIANTE', how='left')\n",
    "rep['materias_repetidas'] = rep['materias_repetidas'].fillna(0).astype(int)\n",
    "feat = feat.merge(rep, on='ESTUDIANTE')\n",
    "\n",
    "# (4) Progreso acad√©mico ‚Äî niveles, per√≠odos, materias distintas\n",
    "prog = df.groupby('ESTUDIANTE').agg(\n",
    "    nivel_max=('NIVEL','max'), nivel_min=('NIVEL','min'),\n",
    "    num_periodos=('PERIODO','nunique'), num_materias_distintas=('MATERIA','nunique'),\n",
    ").reset_index()\n",
    "prog['avance_niveles'] = prog['nivel_max'] - prog['nivel_min']\n",
    "preg = df[~df['PERIODO'].str.contains('ING')].groupby('ESTUDIANTE')['PERIODO'].nunique().reset_index(name='num_periodos_regulares')\n",
    "prog = prog.merge(preg, on='ESTUDIANTE', how='left')\n",
    "prog['num_periodos_regulares'] = prog['num_periodos_regulares'].fillna(0).astype(int)\n",
    "feat = feat.merge(prog, on='ESTUDIANTE')\n",
    "\n",
    "# (5) Se√±ales de alerta ‚Äî materias con nota/asistencia cero\n",
    "alert = df.groupby('ESTUDIANTE').agg(\n",
    "    materias_nota_cero    = ('PROMEDIO',    lambda x: (x == 0).sum()),\n",
    "    materias_asist_cero   = ('ASISTENCIA',  lambda x: (x == 0).sum()),\n",
    "    materias_nota_menor5  = ('PROMEDIO',    lambda x: (x < 5).sum()),\n",
    "    materias_asist_menor50= ('ASISTENCIA',  lambda x: (x < 50).sum()),\n",
    ").reset_index()\n",
    "alert = alert.merge(apr[['ESTUDIANTE','total_materias']], on='ESTUDIANTE')\n",
    "alert['pct_nota_cero']  = alert['materias_nota_cero']  / alert['total_materias']\n",
    "alert['pct_asist_cero'] = alert['materias_asist_cero'] / alert['total_materias']\n",
    "alert.drop(columns='total_materias', inplace=True)\n",
    "feat = feat.merge(alert, on='ESTUDIANTE')\n",
    "\n",
    "# (6) Contexto ‚Äî ingl√©s, movilidad, carga acad√©mica por per√≠odo\n",
    "ing = df[df['MATERIA'].str.contains('INGL√âS', na=False)].groupby('ESTUDIANTE').size().reset_index(name='materias_ingles')\n",
    "esp = especiales.groupby('ESTUDIANTE').size().reset_index(name='registros_especiales') if len(especiales) > 0 else pd.DataFrame(columns=['ESTUDIANTE','registros_especiales'])\n",
    "carga = df.groupby(['ESTUDIANTE','PERIODO']).size().reset_index(name='n')\n",
    "carga = carga.groupby('ESTUDIANTE')['n'].agg(materias_prom_periodo='mean', materias_max_periodo='max').reset_index()\n",
    "feat = feat.merge(ing, on='ESTUDIANTE', how='left')\n",
    "feat = feat.merge(esp, on='ESTUDIANTE', how='left')\n",
    "feat = feat.merge(carga, on='ESTUDIANTE')\n",
    "feat[['materias_ingles','registros_especiales']] = feat[['materias_ingles','registros_especiales']].fillna(0).astype(int)\n",
    "\n",
    "# (7) Tendencia temporal ‚Äî rendimiento en primer vs √∫ltimo per√≠odo\n",
    "est_r = est.rename(columns={'PRIMER_IDX':'P','ULTIMO_IDX':'U'})\n",
    "t1 = df.merge(est_r[['ESTUDIANTE','P']], on='ESTUDIANTE')\n",
    "t1 = t1[t1['PERIODO_IDX'] == t1['P']]\n",
    "pp = t1.groupby('ESTUDIANTE').agg(prom_primer=('PROMEDIO','mean'), asist_primer=('ASISTENCIA','mean')).reset_index()\n",
    "t2 = df.merge(est_r[['ESTUDIANTE','U']], on='ESTUDIANTE')\n",
    "t2 = t2[t2['PERIODO_IDX'] == t2['U']]\n",
    "pu = t2.groupby('ESTUDIANTE').agg(prom_ultimo=('PROMEDIO','mean'), asist_ultimo=('ASISTENCIA','mean')).reset_index()\n",
    "tend = pp.merge(pu, on='ESTUDIANTE')\n",
    "tend['cambio_promedio']    = tend['prom_ultimo']  - tend['prom_primer']\n",
    "tend['cambio_asistencia']  = tend['asist_ultimo'] - tend['asist_primer']\n",
    "feat = feat.merge(tend, on='ESTUDIANTE')\n",
    "\n",
    "# Agregar variable objetivo\n",
    "feat = feat.merge(est[['ESTUDIANTE','DESERTOR']], on='ESTUDIANTE')\n",
    "feat = feat.fillna(0)\n",
    "\n",
    "print(f\"‚úÖ Dataset de modelado creado: {feat.shape[0]} estudiantes √ó {feat.shape[1]} columnas\")\n",
    "print(f\"   Features creados: {feat.shape[1] - 2} (excluyendo ESTUDIANTE y DESERTOR)\")\n",
    "feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23213bba",
   "metadata": {},
   "source": [
    "### Selecci√≥n de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0996fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecci√≥n de features combinando correlaci√≥n de Pearson + informaci√≥n mutua,\n",
    "# eliminando variables redundantes (correlaci√≥n inter-features > 0.90)\n",
    "\n",
    "feature_cols = [c for c in feat.columns if c not in ['ESTUDIANTE','DESERTOR']]\n",
    "X_all, y_all = feat[feature_cols], feat['DESERTOR']\n",
    "\n",
    "# Correlaci√≥n con la variable objetivo\n",
    "corr = X_all.corrwith(y_all).abs()\n",
    "\n",
    "# Informaci√≥n mutua (captura relaciones no lineales)\n",
    "mi = pd.Series(mutual_info_classif(X_all, y_all, random_state=42), index=feature_cols)\n",
    "\n",
    "# Score combinado normalizado\n",
    "cn = (corr - corr.min()) / (corr.max() - corr.min())\n",
    "mn = (mi - mi.min()) / (mi.max() - mi.min())\n",
    "score = ((cn + mn) / 2).sort_values(ascending=False)\n",
    "\n",
    "# Detectar pares de features con alta correlaci√≥n entre s√≠ (multicolinealidad)\n",
    "corr_mat = X_all.corr().abs()\n",
    "upper = corr_mat.where(np.triu(np.ones(corr_mat.shape), k=1).astype(bool))\n",
    "high_pairs = [(c1, c2) for c1 in upper.columns for c2 in upper.index if pd.notna(upper.loc[c2, c1]) and upper.loc[c2, c1] > 0.90]\n",
    "\n",
    "# Seleccionar features de mayor a menor score, descartando los redundantes\n",
    "FEATURES = []\n",
    "descartados = set()\n",
    "for f in score.index:\n",
    "    if f in descartados:\n",
    "        continue\n",
    "    FEATURES.append(f)\n",
    "    for a, b in high_pairs:\n",
    "        if f == a and b not in FEATURES: descartados.add(b)\n",
    "        elif f == b and a not in FEATURES: descartados.add(a)\n",
    "FEATURES = [f for f in FEATURES if score[f] > 0.05]\n",
    "\n",
    "print(f\"FEATURES SELECCIONADOS: {len(FEATURES)}\")\n",
    "print(\"=\" * 60)\n",
    "for i, f in enumerate(FEATURES, 1):\n",
    "    print(f\"  {i:2d}. {f:30s} corr={X_all[f].corr(y_all):+.3f}  MI={mi[f]:.3f}\")\n",
    "print(f\"\\nDescartados por redundancia: {len(descartados)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f2f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 9 ‚Äî Correlaci√≥n de features seleccionados con DESERTOR\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "corr_deser = X_all[FEATURES].corrwith(y_all).sort_values()\n",
    "colores = ['#e74c3c' if v > 0 else '#2ecc71' for v in corr_deser.values]\n",
    "ax.barh(range(len(corr_deser)), corr_deser.values, color=colores, edgecolor='white')\n",
    "ax.set_yticks(range(len(corr_deser)))\n",
    "ax.set_yticklabels(corr_deser.index, fontsize=8)\n",
    "ax.set_xlabel('Correlaci√≥n con DESERTOR')\n",
    "ax.set_title('Features Seleccionados ‚Äî Correlaci√≥n con Deserci√≥n', fontweight='bold')\n",
    "ax.axvline(0, color='black', lw=0.5)\n",
    "for i, v in enumerate(corr_deser.values):\n",
    "    ax.text(v + (0.01 if v >= 0 else -0.01), i, f'{v:.3f}',\n",
    "            va='center', ha='left' if v >= 0 else 'right', fontsize=7, fontweight='bold')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6227175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n train/test estratificada y escalado\n",
    "X = feat[FEATURES].copy()\n",
    "y = feat['DESERTOR'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = pd.DataFrame(scaler.fit_transform(X_train), columns=FEATURES, index=X_train.index)\n",
    "X_test_sc  = pd.DataFrame(scaler.transform(X_test),      columns=FEATURES, index=X_test.index)\n",
    "\n",
    "# SMOTE para balancear clases en entrenamiento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_bal, y_train_bal = smote.fit_resample(X_train_sc, y_train)\n",
    "\n",
    "print(f\"Train original:  {len(X_train)} (activos={int((y_train==0).sum())}, desertores={int((y_train==1).sum())})\")\n",
    "print(f\"Train SMOTE:     {len(X_train_bal)} (activos={int((y_train_bal==0).sum())}, desertores={int((y_train_bal==1).sum())})\")\n",
    "print(f\"Test:            {len(X_test)} (activos={int((y_test==0).sum())}, desertores={int((y_test==1).sum())})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094c0fe",
   "metadata": {},
   "source": [
    "---\n",
    "# FASE 4 ‚Äî Modelado\n",
    "\n",
    "Se entrenan y comparan **4 algoritmos** de clasificaci√≥n:\n",
    "\n",
    "| Modelo | Tipo | Por qu√© se eligi√≥ |\n",
    "|--------|------|-------------------|\n",
    "| Regresi√≥n Log√≠stica | Lineal | Baseline interpretable |\n",
    "| Random Forest | Ensemble (bagging) | Robusto, maneja no linealidades |\n",
    "| Gradient Boosting | Ensemble (boosting) | Alta precisi√≥n en tabulares |\n",
    "| SVM | Kernel | Buen rendimiento en dimensiones moderadas |\n",
    "\n",
    "Todos se eval√∫an con **validaci√≥n cruzada 5-fold** y se prueban en el **test set** (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4e77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar 4 modelos, evaluar con validaci√≥n cruzada y predecir en test\n",
    "modelos = {\n",
    "    'Regresi√≥n Log√≠stica': LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42),\n",
    "    'Random Forest':       RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),\n",
    "    'Gradient Boosting':   GradientBoostingClassifier(n_estimators=200, random_state=42),\n",
    "    'SVM':                 SVC(kernel='rbf', class_weight='balanced', probability=True, random_state=42),\n",
    "}\n",
    "\n",
    "resultados = {}\n",
    "predicciones = {}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    print(f\"\\n{'='*55}\")\n",
    "    print(f\"  {nombre}\")\n",
    "    print(f\"{'='*55}\")\n",
    "\n",
    "    # Validaci√≥n cruzada en el train balanceado\n",
    "    f1_cv = cross_val_score(modelo, X_train_bal, y_train_bal, cv=cv, scoring='f1')\n",
    "    print(f\"  F1 CV (5-fold): {f1_cv.mean():.4f} ¬± {f1_cv.std():.4f}\")\n",
    "\n",
    "    # Entrenar y predecir en test\n",
    "    modelo.fit(X_train_bal, y_train_bal)\n",
    "    y_pred = modelo.predict(X_test_sc)\n",
    "    y_prob = modelo.predict_proba(X_test_sc)[:, 1]\n",
    "\n",
    "    acc  = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec  = recall_score(y_test, y_pred)\n",
    "    f1   = f1_score(y_test, y_pred)\n",
    "    auc  = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "    resultados[nombre] = {'Accuracy': acc, 'Precision': prec, 'Recall': rec, 'F1-Score': f1, 'AUC-ROC': auc, 'F1_CV': f1_cv.mean()}\n",
    "    predicciones[nombre] = {'y_pred': y_pred, 'y_prob': y_prob, 'modelo': modelo}\n",
    "\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    print(f\"  AUC-ROC:   {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00835fe7",
   "metadata": {},
   "source": [
    "---\n",
    "# FASE 5 ‚Äî Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b810a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla comparativa de modelos, ordenada por F1-Score\n",
    "df_res = pd.DataFrame(resultados).T.sort_values('F1-Score', ascending=False)\n",
    "mejor_nombre = df_res.index[0]\n",
    "\n",
    "print(\"COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\" * 75)\n",
    "print(df_res.round(4).to_string())\n",
    "print(f\"\\nüèÜ Mejor modelo: {mejor_nombre} (F1={df_res.loc[mejor_nombre, 'F1-Score']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40fa4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 10 ‚Äî Comparaci√≥n de m√©tricas entre modelos (barras agrupadas)\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "metricas = ['Accuracy','Precision','Recall','F1-Score','AUC-ROC']\n",
    "x = np.arange(len(metricas))\n",
    "width = 0.18\n",
    "colores_m = ['#3498db','#2ecc71','#e67e22','#9b59b6']\n",
    "\n",
    "for i, (nombre, vals) in enumerate(df_res.iterrows()):\n",
    "    v = [vals[m] for m in metricas]\n",
    "    bars = ax.bar(x + i * width, v, width, label=nombre, color=colores_m[i], edgecolor='white')\n",
    "    for b, val in zip(bars, v):\n",
    "        ax.text(b.get_x() + b.get_width()/2, val + 0.01, f'{val:.2f}', ha='center', fontsize=7)\n",
    "\n",
    "ax.set_xticks(x + width * 1.5); ax.set_xticklabels(metricas)\n",
    "ax.set_ylim(0, 1.15); ax.set_title('Comparaci√≥n de Modelos', fontweight='bold')\n",
    "ax.legend(loc='upper right'); ax.set_ylabel('Score')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 11 ‚Äî Matrices de confusi√≥n de los 4 modelos\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 4))\n",
    "for ax, (nombre, data) in zip(axes, predicciones.items()):\n",
    "    cm = confusion_matrix(y_test, data['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, annot_kws={'size': 14},\n",
    "                xticklabels=['Activo','Desertor'], yticklabels=['Activo','Desertor'])\n",
    "    ax.set_title(nombre, fontweight='bold', fontsize=10)\n",
    "    ax.set_ylabel('Real'); ax.set_xlabel('Predicho')\n",
    "plt.suptitle('Matrices de Confusi√≥n', fontweight='bold', fontsize=14, y=1.02)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c55f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 12 ‚Äî Curvas ROC\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "colores_roc = ['#3498db','#2ecc71','#e67e22','#9b59b6']\n",
    "for (nombre, data), color in zip(predicciones.items(), colores_roc):\n",
    "    fpr, tpr, _ = roc_curve(y_test, data['y_prob'])\n",
    "    auc_val = roc_auc_score(y_test, data['y_prob'])\n",
    "    ax.plot(fpr, tpr, color=color, lw=2, label=f'{nombre} (AUC={auc_val:.3f})')\n",
    "ax.plot([0,1], [0,1], 'k--', lw=1, alpha=0.5)\n",
    "ax.set_xlabel('Tasa de Falsos Positivos'); ax.set_ylabel('Tasa de Verdaderos Positivos')\n",
    "ax.set_title('Curvas ROC', fontweight='bold'); ax.legend(loc='lower right')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3ff3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico 13 ‚Äî Importancia de variables del mejor modelo\n",
    "mejor_mod = predicciones[mejor_nombre]['modelo']\n",
    "\n",
    "if hasattr(mejor_mod, 'feature_importances_'):\n",
    "    imp = pd.Series(mejor_mod.feature_importances_, index=FEATURES).sort_values()\n",
    "elif hasattr(mejor_mod, 'coef_'):\n",
    "    imp = pd.Series(np.abs(mejor_mod.coef_[0]), index=FEATURES).sort_values()\n",
    "else:\n",
    "    imp = mi[FEATURES].sort_values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "ax.barh(range(len(imp)), imp.values, color='#2980b9', edgecolor='white')\n",
    "ax.set_yticks(range(len(imp))); ax.set_yticklabels(imp.index, fontsize=8)\n",
    "ax.set_xlabel('Importancia')\n",
    "ax.set_title(f'Importancia de Variables ‚Äî {mejor_nombre}', fontweight='bold')\n",
    "for i, v in enumerate(imp.values):\n",
    "    ax.text(v + 0.002, i, f'{v:.4f}', va='center', fontsize=7)\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969a5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de clasificaci√≥n detallado del mejor modelo\n",
    "print(f\"REPORTE DE CLASIFICACI√ìN ‚Äî {mejor_nombre}\")\n",
    "print(\"=\" * 55)\n",
    "print(classification_report(y_test, predicciones[mejor_nombre]['y_pred'],\n",
    "                            target_names=['Activo (0)', 'Desertor (1)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizaci√≥n de hiperpar√°metros del mejor modelo con GridSearchCV\n",
    "if 'Random Forest' in mejor_nombre:\n",
    "    param_grid = {'n_estimators':[100,200,300], 'max_depth':[5,10,15,None], 'min_samples_split':[2,5,10]}\n",
    "    gs = GridSearchCV(RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "                      param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "elif 'Gradient' in mejor_nombre:\n",
    "    param_grid = {'n_estimators':[100,200,300], 'max_depth':[3,5,7], 'learning_rate':[0.05,0.1,0.2]}\n",
    "    gs = GridSearchCV(GradientBoostingClassifier(random_state=42),\n",
    "                      param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "elif 'SVM' in mejor_nombre:\n",
    "    param_grid = {'C':[0.1,1,10], 'gamma':['scale','auto'], 'kernel':['rbf','poly']}\n",
    "    gs = GridSearchCV(SVC(class_weight='balanced', probability=True, random_state=42),\n",
    "                      param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "else:\n",
    "    param_grid = {'C':[0.01,0.1,1,10], 'penalty':['l1','l2'], 'solver':['saga']}\n",
    "    gs = GridSearchCV(LogisticRegression(max_iter=2000, class_weight='balanced', random_state=42),\n",
    "                      param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train_bal, y_train_bal)\n",
    "modelo_final = gs.best_estimator_\n",
    "y_pred_opt = modelo_final.predict(X_test_sc)\n",
    "\n",
    "print(f\"Mejores hiperpar√°metros: {gs.best_params_}\")\n",
    "print(f\"F1 optimizado en test: {f1_score(y_test, y_pred_opt):.4f}\")\n",
    "print(f\"Recall optimizado:     {recall_score(y_test, y_pred_opt):.4f}\")\n",
    "print(f\"Accuracy optimizado:   {accuracy_score(y_test, y_pred_opt):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420ce2a",
   "metadata": {},
   "source": [
    "---\n",
    "# FASE 6 ‚Äî Despliegue\n",
    "\n",
    "Se exportan todos los artefactos necesarios para la aplicaci√≥n Streamlit:\n",
    "- `modelo_desercion.pkl` ‚Äî Modelo entrenado optimizado\n",
    "- `scaler.pkl` ‚Äî Escalador entrenado\n",
    "- `features.pkl` ‚Äî Lista de features en orden\n",
    "- `resultados_modelos.pkl` ‚Äî M√©tricas de todos los modelos\n",
    "- `dataset_modelado.csv` ‚Äî Dataset procesado por estudiante\n",
    "- `feature_importances.csv` ‚Äî Importancia de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497441c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar artefactos para Streamlit\n",
    "joblib.dump(modelo_final, 'modelo_desercion.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(FEATURES, 'features.pkl')\n",
    "joblib.dump(dict(resultados), 'resultados_modelos.pkl')\n",
    "feat.to_csv('dataset_modelado.csv', index=False)\n",
    "\n",
    "# Importancias del modelo final\n",
    "if hasattr(modelo_final, 'feature_importances_'):\n",
    "    imp_final = pd.Series(modelo_final.feature_importances_, index=FEATURES)\n",
    "elif hasattr(modelo_final, 'coef_'):\n",
    "    imp_final = pd.Series(np.abs(modelo_final.coef_[0]), index=FEATURES)\n",
    "else:\n",
    "    imp_final = mi[FEATURES]\n",
    "imp_final.to_csv('feature_importances.csv')\n",
    "\n",
    "# Guardar y_test y predicciones para reproducibilidad\n",
    "pd.DataFrame({'y_test': y_test.values, 'y_pred': y_pred_opt}).to_csv('test_predictions.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Artefactos exportados:\")\n",
    "for f in ['modelo_desercion.pkl','scaler.pkl','features.pkl','resultados_modelos.pkl',\n",
    "          'dataset_modelado.csv','feature_importances.csv','test_predictions.csv']:\n",
    "    print(f\"   üì¶ {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9738f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descargar todos los archivos para usar con Streamlit (solo en Colab)\n",
    "from google.colab import files\n",
    "for f in ['modelo_desercion.pkl','scaler.pkl','features.pkl','resultados_modelos.pkl',\n",
    "          'dataset_modelado.csv','feature_importances.csv','test_predictions.csv']:\n",
    "    files.download(f)\n",
    "print(\"\\n‚úÖ Todos los archivos descargados. Col√≥calos junto a app.py para ejecutar Streamlit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7b606",
   "metadata": {},
   "source": [
    "---\n",
    "## Conclusiones\n",
    "\n",
    "1. Se aplic√≥ la **metodolog√≠a CRISP-DM** completa sobre el dataset de record estudiantil (4,448 registros, 488 estudiantes).\n",
    "2. Se defini√≥ la variable objetivo **DESERTOR** a partir del √∫ltimo per√≠odo de matr√≠cula: 208 desertores (42.6%) vs 280 activos (57.4%).\n",
    "3. Se crearon **40+ features** agregados a nivel de estudiante, seleccionando los m√°s relevantes mediante correlaci√≥n de Pearson e informaci√≥n mutua, eliminando multicolinealidad.\n",
    "4. Se evaluaron **4 modelos** de clasificaci√≥n con validaci√≥n cruzada 5-fold y SMOTE para balanceo.\n",
    "5. El mejor modelo fue **optimizado** con GridSearchCV y exportado para la aplicaci√≥n Streamlit.\n",
    "6. Los **factores m√°s predictivos** de deserci√≥n son: tasa de reprobaci√≥n, materias aprobadas, promedio acad√©mico y asistencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
